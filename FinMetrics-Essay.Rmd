---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Dynamic Portfolio Optimization Across Asset Classes using Multi-variate Volatility Modelling"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Carel Olivier"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "22017542" # First Author's Affiliation
Email1: "22017542\\@sun.ac.za" # First Author's Email address


# Comment out below to remove both. JEL Codes only given if keywords also given.
keywords: "Multivariate GARCH \\sep DCC \\sep Go-GARCH \\sep Portfolio Optimization" # Use \\sep to separate
#JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

pacman::p_load("tidyverse", "devtools", "rugarch", "rmgarch", "zoo", "factoextra",
               "forecast", "tbl2xts", "lubridate", "PerformanceAnalytics",
               "ggthemes", "dplyr", "cowplot", "fmxdat", "glue","MTS",
               "robustbase","tidyr", "purrr")


```


# Introduction \label{Introduction}

The idea of asset co-movements is important to investors because they provide insight into the underlying relationships between assets and the risk and return characteristics of a portfolio, which can inform investment decisions and help to improve portfolio performance. In particular, portfolio diversification helps to reduce the risk of large losses by spreading investments across a variety of assets and can lead to increased returns by providing exposure to a wider range of economic and market conditions [@briere2012no].

A large body of literature has investigated the effect of the Global Financial Crisis (GFC) on the relationship across various asset classes [@mensi2016global; @zhang2020global]. These studies have shown how the GFC has intensified market relations and affected asset allocation and hedging strategies. As such, fluctuations in interdependence across financial markets can greatly affect investors seeking diversification benefits.

Several studies have examined the time-varying correlations between asset classes in South Africa using various techniques. @bouri2021return, for example, studied the dynamic connectedness across five assets using the TVP-VAR connectedness approach. @bouri2021return shows that total connectedness spiked around the COVID-19 outbreak, which subsequently altered the structure of the network of connectedness and posed a threat to investors’ portfolios. @horvath2012international studied the conditional correlation between sectors of numerous economies, including South Africa, using the BEKK MV-GARCH approach. @duncan2013domestic used generalised variance decompositions of a vector autoregressive model to study the time-varying domestic and foreign volatility spillovers and evolving linkages across asset classes in South Africa and global capital markets.

The analysis in this paper is divided into two parts. First, I will analyse the time-varying conditional correlations between the different asset classes by using @engle2002dynamic Dynamic Conditional Correlation (DCC) Model as well as a GO-GARCH model. DCC models are statistical models used in finance and economics to capture the changing correlations between multiple time series. These models allow for changes in the correlations between time series over time, which is important in modelling the behaviour of assets that are dependent on each other [@engle2002dynamic]. DCC models use a multivariate GARCH framework to capture the dynamics of the covariance matrix of the series over time.

The second part of the analysis will focus on portfolio optimization. Portfolio optimization is the process of determining the optimal allocation of assets in a portfolio in order to maximize returns or minimize risk. This typically involves using mathematical models to identify the portfolio that offers the best trade-off between risk and return, taking into account constraints such as investment budgets and risk tolerance [@ledoit2003improved]. The optimization process takes into account factors such as expected returns, volatilities, and correlations between assets in order to determine the optimal portfolio mix.

# Methodology

## DCC specification

The method behind DCC models is based on the idea of modeling the covariance matrix of the returns of multiple assets over time. For @engle2002dynamic DCC model the variance-covariance matrix can be written as ^[The paper was written using the 'Texevier' package developed by N.F. Katzke (2016)]:


\begin{equation} \label{dcc}
H_t = D_t.R_t.D_t.
\end{equation}

Estimating $R_T$ now requires it to be inverted at each estimated period, and thus a proxy equation is used:

\begin{align}  \label{dcc2}
  Q_{ij,t} &= \bar Q + a\left(z_{t - 1}z'_{t - 1} - \bar{Q} \right) + b\left( Q_{ij, t - 1} - \bar{Q} \right) \hfill \\ \notag
        &= (1 - a - b)\bar{Q} + az_{t - 1}z'_{t - 1} + b.Q_{ij, t - 1} \notag
\end{align}

With non-negative scalars $a$ and $b$, and with:

* $Q_{ij, t}$ the unconditional (sample) variance estimate between series $i$ and $j$ ,

* $\bar{Q}$ the unconditional matrix of standardized residuals from each univariate pair estimate.

We next estimate $R_T$ as:

\begin{align}\label{eq:dcc3}
R_t &= diag(Q_t)^{-1/2}Q_t.diag(Q_t)^{-1/2}. 
\end{align}

The dynamic conditional correlation matrix, will therefore have entries in the bivariate framework as follows:

\begin{align}
R_t &= \rho_{ij,t} = \frac{q_{i,j,t}}{\sqrt{q_{ii,t}.q_{jj,t}}} 
\end{align}



## Go-GARCH specification

The methodology behind Go-GARCH models is based on a combination of the GARCH (Generalized Autoregressive Conditional Heteroskedasticity) framework and the concept of orthogonalization. Orthogonalization is used to ensure that the parameters of the model are estimated in an uncorrelated and unbiased manner. This can help to improve the stability and accuracy of the model's predictions.

These orthogonal components are measured by identifying independent and uncorrelated factors that make up the var-covar matrix $H_t$. The statistical transformations are done as follows:

\begin{align}
r_t &= \mu_t +\varepsilon_t  \\
\varepsilon_t &= A.f_t 
\end{align}

with $A$ linking the unobserved uncorrelated components with the observed residual process. Also: $f_t$ represents the unobserved independent factors assigned to each series (factor weights), such that:

\begin{align}
    f_t = H^{1/2}.z_t
\end{align}

with $H_T$ and $z_t$ as before and:

\begin{align}
E[f_t] &= 0 ; \qquad \qquad E[f_tf_t'] = I_N \notag \\
E[\varepsilon_t] &= 0 ; \qquad \qquad E[\varepsilon_t\varepsilon_t'] = AA'
\end{align}

So that the conditional covariance matrix is given by:

\begin{align}
    \Sigma_t=AH_tA'
\end{align}


# Data

My objective is to characterise the time-varying correlation estimates to provide insight into the underlying comovement structures of a portfolio of asset classes. The empirical application in this paper aims to diversify a portfolio investing in stocks, property, gold, and Bitcoin. This study collects daily price data on the FTSE/JSE Africa All Share Index, FTSE/JSE Africa Property Index, gold, and Bitcoin ^[All the data was obtained from the 'fmxdat' package in R]. The sample period of this study covers data from the beginning of 2015 to the end of 2019. Considering a time series of prices, the daily asset returns are calculated by taking the log difference of each index series, as:

\begin{align} 
  r_{i,t} &= ln(\frac{P_{i,t}}{P_{i,t-1}}) * 100
\end{align}

Where $P_{i,t}$ is the closing price of the index, $i$, at time $t$. Logarithmic returns are usually preferred by financial econometricians because of their superior properties compared to arithmetic returns.

In order to analyse the characteristics of the data for the return series, I first produce a chart of the price and return series. The two figures below shows the closing prices and returns of the four asset classes, respectively. We can see from the second figure that the return series exhibit volatility clustering.


```{r}
# Import Data

bonds_raw <- read_rds("data/SA_Bonds.rds")

Indexes_raw <- fmxdat::SA_Indexes

gold_raw <- read_rds("data/comms.rds")

bitcoin_raw <- fmxdat::cryptos

# Filter relevant indexes
# Equities and Property

Indexes <- Indexes_raw %>%

    arrange(date) %>%

    dplyr::filter(Tickers %in% c("JALSHTR Index", "JSAPYTR Index")) %>%

    select(-ShareName)

colnames(Indexes) = c("date","Ticker","Price")

# Gold
Gold <- gold_raw %>%

    arrange(date) %>%

    dplyr::filter(Name %in% "Gold")

colnames(Gold) = c("date","Ticker","Price")

# Bitcoin

Bitcoin <- bitcoin_raw %>%

    arrange(date) %>%

    dplyr::filter(name %in% "Bitcoin") %>%

    select(date, name, close)

colnames(Bitcoin) = c("date","Ticker","Price")

# Combine data

asset_classes <- rbind(Indexes, Gold, Bitcoin)

# Calculate Return
library(rmsfuns)

datescol <- dateconverter(as.Date("2015-01-01"), as.Date("2019-12-31"),
                          "weekdayEOW")

asset_classes_ret <- asset_classes %>%

    group_by(Ticker) %>%
    
    mutate(dlogret = log(Price) - log(dplyr::lag(Price))) %>%

    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T)))  %>%

    dplyr::filter(date > dplyr::first(date)) %>%

    dplyr::filter(date %in% datescol) %>% 

    ungroup()


# Graph
# check for obvious outliers in the returns series:

#ggplot(asset_classes_ret) +

#    geom_line(aes(x = date, y = Price, colour = Ticker,
#                                alpha = 0.5)) +

#    ggtitle("Price Changes: Asset Classes") +

#    guides(alpha = "none") +

#    fmxdat::theme_fmx()


# Or cleaning the plot up a bit....

ggplot(asset_classes_ret) +

    geom_line(aes(x = date, y = Price, colour = Ticker,
                                alpha = 0.5)) +

    ggtitle("Price Changes: Asset Classes") +

    facet_wrap(~Ticker, scales = "free_y") +

    guides(alpha = "none") +

    fmxdat::theme_fmx() +

    scale_color_hue(l = 20) +

    scale_x_date(labels = scales::date_format("'%y"), date_breaks = "2 years") +

    theme(axis.text = element_text(size = 7))

```


```{r}
# log returns

ggplot(asset_classes_ret) +

    geom_line(aes(x = date,y =dlogret, color = Ticker, alpha = 0.5)) +

    ggtitle("Log Returns: Asset Classes") +

    facet_wrap(~Ticker, scales = "free") +

    guides(fill = "none", alpha = "none") +

    fmxdat::theme_fmx()

```


Next, I examine the Autoregressive Conditional Heteroskedasticity (ARCH) effects. To visualize the analysis of autocorrelations in the residuals and squared residuals, I graph the returns, squared returns and the absolute returns for an equally weighted portfolio of the assets using simple returns.

```{r}
# It seems that there is large clumping together of returns.
#This might bias our model estimates (especially if it is only a few outliers).
# So I'll clean data

pacman::p_load(PerformanceAnalytics)

Tidy_asset_rtn <-

    left_join(

        asset_classes_ret,

        asset_classes_ret %>%

            tbl_xts(., cols_to_xts = "dlogret", spread_by = "Ticker") %>%

            PerformanceAnalytics::Return.clean(., method = c("none", "boudt", "geltner")[2], alpha = 0.01) %>%

            tbl2xts::xts_tbl() %>%

            gather(Ticker, CleanedRet, -date),

        by = c("date", "Ticker")
    )

# Now let's see what changed:
#Tidy_asset_rtn %>% dplyr::filter(CleanedRet != dlogret)

# The MARCH test indicates that all the MV portmanteau tests reject the
# null of no conditional heteroskedasticity, motivating our use of MVGARCH models.

#Auto-Persistence in Returns

# Create the Simple returns:

Simple_asset_rtn <- asset_classes_ret %>%

    group_by(Ticker) %>%

    mutate(SimpleRet = Price / dplyr::lag(Price)-1) %>%

    ungroup() %>%

    mutate(date = lubridate::ymd(date)) %>% # Easier to work with ymd here

    tbl_xts(., cols_to_xts = SimpleRet, spread_by = Ticker)

Simple_asset_rtn[is.na(Simple_asset_rtn)] <- 0


Weights <- asset_classes_ret %>%

    mutate(YM = format(date, "%Y%b")) %>%

    group_by(YM) %>%

    dplyr::filter(date == last(date)) %>%

    mutate(weight = 1/n()) %>%

    ungroup() %>%

    select(date, Ticker, weight) %>%

    unique %>%

    mutate(date = lubridate::ymd(date)) %>% # Easier to work with ymd here

    tbl_xts(., spread_by = Ticker)

Weights[is.na(Weights)] <- 0


porteqw <- rmsfuns::Safe_Return.portfolio(Simple_asset_rtn, weight = Weights,
                                          geometric = FALSE)
```

```{r}
# ACF's

forecast::Acf(porteqw, main = "ACF: Equally Weighted Return")
```

```{r}
forecast::Acf(porteqw^2, main = "ACF: Squared Equally Weighted Return")
```

```{r}
forecast::Acf(abs(porteqw), main = "ACF: Absolute Equally Weighted Return")

# A formal test for ARCH effects: LBQ stats on squared returns:

#Box.test(coredata(porteqw^2), type = "Ljung-Box", lag = 12)

```



The above figure displays a pattern of squared residuals, which indicates strong conditional heteroskedasticity. In addition, I formally test for ARCH effects using a Ljung–Box test which rejected the null of no ARCH effects - hence I need to control for the remaining conditional heteroskedasticity in the returns series.

# DCC model

Before fitting the most appropriate univariate GARCH specifications to each series, I check and clean the data for any missing values and outliers. Thereafter, I specify a GARCH model for each time series, which is used as the conditional covariance structure in the DCC model. Finally, I compute the dynamic correlations between each pair of assets.

```{r, include=FALSE}
# Calculate Returns for Assets

# equity

Equities <- Indexes %>%

    group_by(Ticker) %>%

    dplyr::filter(Ticker %in% "JALSHTR Index") %>%

    mutate(dlogret = log(Price) - log(dplyr::lag(Price))) %>%

    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>%

    dplyr::filter(date > dplyr::first(date)) %>%

    select(-Price) %>%

    dplyr::filter(date > as.Date("2014-12-31")) %>%

    rename("JALSHTR_Index" = dlogret) %>%

    ungroup() %>%

    select(date, JALSHTR_Index)

# property

Property <- Indexes %>%

    group_by(Ticker) %>%

    dplyr::filter(Ticker %in% "JSAPYTR Index") %>%

    mutate(dlogret = log(Price) - log(dplyr::lag(Price))) %>%

    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>%

    dplyr::filter(date > dplyr::first(date)) %>%

    select(-Price) %>%

    dplyr::filter(date > as.Date("2014-12-31")) %>%

    rename("JSAPYTR_Index" = dlogret) %>%

    ungroup() %>%

    select(date, JSAPYTR_Index)

# gold

Gold_ret <- gold_raw %>%

    group_by(Name) %>%

    dplyr::filter(Name %in% "Gold") %>%

    mutate(dlogret = log(Price) - log(dplyr::lag(Price))) %>%

    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>%

    dplyr::filter(date > dplyr::first(date)) %>%

    select(-Price) %>%

    dplyr::filter(date > as.Date("2014-12-31")) %>%

    rename("Gold" = dlogret) %>%

    ungroup() %>%

    select(date, Gold)


# bitcoin

Bit_ret <- Bitcoin %>%

    mutate(dlogret = log(Price) - log(dplyr::lag(Price))) %>%

    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>%

    dplyr::filter(date > dplyr::first(date)) %>%

    select(-Price) %>%

    dplyr::filter(date > as.Date("2014-12-31")) %>%

    rename("Bitcoin" = dlogret) %>%

    select(date, Bitcoin)

# Combine and wrangle for DCC models

asset_xts_ret <- left_join(Equities, Property, by = c("date")) %>%

    left_join(., Gold_ret, by = c("date")) %>%

    left_join(., Bit_ret, by = c("date")) %>%

    tbl_xts()

asset_xts_ret <- asset_xts_ret %>%

    xts_tbl() %>%

    dplyr::filter(date < as.Date("2020-01-01")) %>%

    tbl_xts()

asset_tbl_ret <- asset_xts_ret %>% xts_tbl()


asset_xts_ret <- na.locf(asset_xts_ret, na.rm = F, maxgap = 10)

# Lets test for autocorrelation using the March Test

MarchTest(asset_xts_ret)

# GARCH specifications

uspec <- ugarchspec(variance.model = list(model = "gjrGARCH",
                                          garchOrder = c(1, 1)), mean.model = list(armaOrder = c(1,
                                                                                                 0), include.mean = TRUE), distribution.model = "sstd")

multi_univ_garch_spec <- multispec(replicate(ncol(asset_xts_ret), uspec))

# DCC specifications

spec.dcc = dccspec(multi_univ_garch_spec, dccOrder = c(1, 1),
                   distribution = "mvnorm", lag.criterion = c("AIC", "HQ", "SC",
                                                              "FPE")[1], model = c("DCC", "aDCC")[1])

# Enable clustering for speed:

cl = makePSOCKcluster(10)

# Fit GARCH

multf = multifit(multi_univ_garch_spec, asset_xts_ret, cluster = cl)

# Fit DCC

fit.dcc = dccfit(spec.dcc, data = asset_xts_ret, solver = "solnp",
                 cluster = cl, fit.control = list(eval.se = FALSE), fit = multf)

# Check Model

RcovList <- rcov(fit.dcc)

covmat = matrix(RcovList, nrow(asset_xts_ret), ncol(asset_xts_ret) * ncol(asset_xts_ret),
                byrow = TRUE)

mc1 = MCHdiag(asset_xts_ret, covmat)


# Wrangle output
dcc.time.var.cor <- rcor(fit.dcc)
print(dcc.time.var.cor[, , 1:3])

dcc.time.var.cor <- aperm(dcc.time.var.cor, c(3, 2, 1))
dim(dcc.time.var.cor) <- c(nrow(dcc.time.var.cor), ncol(dcc.time.var.cor)^2)

# Rename Output
renamingdcc <- function(ReturnSeries, DCC.TV.Cor) {

    ncolrtn <- ncol(ReturnSeries)
    namesrtn <- colnames(ReturnSeries)
    paste(namesrtn, collapse = "_")

    nam <- c()
    xx <- mapply(rep, times = ncolrtn:1, x = namesrtn)
    # Now let's be creative in designing a nested for loop to save the names corresponding to the columns of interest..

    # TIP: draw what you want to achieve on a paper first. Then apply code.

    # See if you can do this on your own first.. Then check vs my solution:

    nam <- c()
    for (j in 1:(ncolrtn)) {
        for (i in 1:(ncolrtn)) {
            nam[(i + (j-1)*(ncolrtn))] <- paste(xx[[j]][1], xx[[i]][1], sep="_")
        }
    }

    colnames(DCC.TV.Cor) <- nam

    # So to plot all the time-varying correlations wrt SBK:
    # First append the date column that has (again) been removed...
    DCC.TV.Cor <-
        data.frame( cbind( date = index(ReturnSeries), DCC.TV.Cor)) %>% # Add date column which dropped away...
        mutate(date = as.Date(date)) %>%  tbl_df()

    DCC.TV.Cor <- DCC.TV.Cor %>% gather(Pairs, Rho, -date)

    DCC.TV.Cor

}

dcc.time.var.cor <- renamingdcc(ReturnSeries = asset_xts_ret, DCC.TV.Cor = dcc.time.var.cor)

# plot equity

DCC_eq_plot <- ggplot(dcc.time.var.cor %>%

                          dplyr::filter(grepl("JSAPYTR_Index_", Pairs),
                                 !grepl("_JSAPYTR_Index", Pairs))) +

    geom_line(aes(x = date, y = Rho, colour = Pairs)) +

    theme_hc() + labs(subtitle = "Dynamic Conditional Correlations: JALSHTR_Index", x = "", y = "") +

    fmx_cols() +

    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))

plot_grid(DCC_eq_plot, labels = c(''))


###################################

DCCPre <- dccPre(asset_xts_ret, include.mean = T, p = 0)

names(DCCPre)

# We now have the estimates of volatility for each series.

Vol <- DCCPre$marVol

colnames(Vol) <- colnames(asset_xts_ret)

Vol <-
    data.frame( cbind( date = index(asset_xts_ret), Vol)) %>%

    mutate(date = as.Date(date)) %>%

    tbl_df()

TidyVol <- Vol %>%

    gather(Stocks, Sigma, -date)

ggplot(TidyVol) + geom_line(aes(x = date, y = Sigma, colour = Stocks))

# ------- Back to DCC:

# After saving now the standardized residuals:
StdRes <- DCCPre$sresi

detach("package:tidyverse", unload=TRUE)
detach("package:tbl2xts", unload=TRUE)

DCC <- dccFit(StdRes, type="Engle")

pacman::p_load("tidyverse", "tbl2xts", "broom")

Rhot <- DCC$rho.t
# Right, so it gives us all the columns together in the form:
# X1,X1 ; X1,X2 ; X1,X3 ; ....

# So, let's be clever about defining more informative col names.
# I will create a renaming function below:
ReturnSeries = asset_xts_ret
DCC.TV.Cor = Rhot

renamingdcc <- function(ReturnSeries, DCC.TV.Cor) {

    ncolrtn <- ncol(ReturnSeries)
    namesrtn <- colnames(ReturnSeries)
    paste(namesrtn, collapse = "_")

    nam <- c()
    xx <- mapply(rep, times = ncolrtn:1, x = namesrtn)
    # Now let's be creative in designing a nested for loop to save the names corresponding to the columns of interest..

    # TIP: draw what you want to achieve on a paper first. Then apply code.

    # See if you can do this on your own first.. Then check vs my solution:

    nam <- c()
    for (j in 1:(ncolrtn)) {
        for (i in 1:(ncolrtn)) {
            nam[(i + (j-1)*(ncolrtn))] <- paste(xx[[j]][1], xx[[i]][1], sep="_")
        }
    }

    colnames(DCC.TV.Cor) <- nam

    # So to plot all the time-varying correlations wrt SBK:
    # First append the date column that has (again) been removed...
    DCC.TV.Cor <-
        data.frame( cbind( date = index(ReturnSeries), DCC.TV.Cor)) %>% # Add date column which dropped away...
        mutate(date = as.Date(date)) %>%  tbl_df()

    DCC.TV.Cor <- DCC.TV.Cor %>% gather(Pairs, Rho, -date)

    DCC.TV.Cor

}

# Let's see if our function works! Excitement!
Rhot <- renamingdcc(ReturnSeries = asset_xts_ret, DCC.TV.Cor = Rhot)

head(Rhot %>% arrange(date))

# Let's now create a plot for all the stocks relative to the other stocks...
#property

gg_property <-
    ggplot(Rhot %>%

               dplyr::filter(grepl("JSAPYTR_Index_", Pairs ),
                      !grepl("_JSAPYTR_Index", Pairs)) ) +
    geom_line(aes(x = date, y = Rho, colour = Pairs)) +
    theme_hc() +
    ggtitle("Dynamic Conditional Correlations: JSAPYTR_Index")

print(gg_property)

# equity
gg_equity <-
    ggplot(Rhot %>%

               dplyr::filter(grepl("JALSHTR_Index_", Pairs ),
                      !grepl("_JALSHTR_Index", Pairs)) ) +
    geom_line(aes(x = date, y = Rho, colour = Pairs)) +
    theme_hc() +
    ggtitle("Dynamic Conditional Correlations: JALSHTR_Index")

print(gg_equity)

# Gold

gg_gold <-
    ggplot(Rhot %>%

               dplyr::filter(grepl("Gold_", Pairs ),
                      !grepl("_Gold", Pairs)) ) +
    geom_line(aes(x = date, y = Rho, colour = Pairs)) +
    theme_hc() +
    ggtitle("Dynamic Conditional Correlations: Gold")

print(gg_gold)

# Bitcoin

gg_bitcoin <-
    ggplot(Rhot %>%

               dplyr::filter(grepl("Bitcoin_", Pairs ),
                      !grepl("_Bitcoin", Pairs)) ) +
    geom_line(aes(x = date, y = Rho, colour = Pairs)) +
    theme_hc() +
    ggtitle("Dynamic Conditional Correlations: Bitcoin")

print(gg_bitcoin)

```


```{r}
print(gg_equity)
```


```{r}
print(gg_property)
```


```{r}
print(gg_gold)
```


```{r}
print(gg_bitcoin)
```


```{r}
# combine dcc plots

#plot_grid(finplot(gg_equity), finplot(gg_property),

#          finplot(gg_gold), finplot(gg_bitcoin),

#          labels = list(title = ""),
#          label_size = ggpts(25), align = "h")
```


The figures above illustrate the evolution of correlation processes over time. Some asset pairs show correlations that are very volatile and some that flow from positive to negative, or from negative to positive. It indicates that the diversification potential changes over time.

# Go-GARCH

Generalized Orthogonal GARCH (GO-GARCH) models are used to model and forecast volatility in financial time series data. GO-GARCH models are an extension of the popular GARCH (Generalized Autoregressive Conditional Heteroskedasticity) models and combine features of both ARCH (Autoregressive Conditional Heteroskedasticity) and GARCH models. GO-GARCH models are characterized by using orthogonal (uncorrelated) innovations in the GARCH process, which results in a reduced number of parameters compared to traditional GARCH models [@boswijk2006wake]. This makes the GO-GARCH models computationally more efficient and easier to estimate. Additionally, the use of orthogonal innovations can lead to better forecasting performance, especially in situations where the underlying volatility process is highly non-linear.

The figure below depict the time-varying correlations between the asset classes using a GO-GARCH model.

```{r, include=FALSE}
# Go-garch

# Now we create a gogarch model specification:
spec.go <- gogarchspec(multi_univ_garch_spec,
                       distribution.model = 'mvnorm', # or manig.
                       ica = 'fastica') # Note: we use the fastICA
cl <- makePSOCKcluster(10)
multf <- multifit(multi_univ_garch_spec, asset_xts_ret, cluster = cl)

fit.gogarch <- gogarchfit(spec.go,
                          data = asset_xts_ret,
                          solver = 'hybrid',
                          cluster = cl,
                          gfun = 'tanh',
                          maxiter1 = 40000,
                          epsilon = 1e-08,
                          rseed = 100)

print(fit.gogarch)

# Extracting time-varying conditional correlations: You know the drill...
gog.time.var.cor <- rcor(fit.gogarch)

gog.time.var.cor <- aperm(gog.time.var.cor,c(3,2,1))

dim(gog.time.var.cor) <- c(nrow(gog.time.var.cor), ncol(gog.time.var.cor)^2)

# Finally:
gog.time.var.cor <-
    renamingdcc(ReturnSeries = asset_xts_ret, DCC.TV.Cor = gog.time.var.cor)

# plot go garch

gg_go_equity <- ggplot(gog.time.var.cor %>% dplyr::filter(grepl("JALSHTR_Index_", Pairs),
                                         !grepl("_JALSHTR_Index", Pairs))) +
    geom_line(aes(x = date, y = Rho,
                 colour = Pairs)) + theme_hc() + ggtitle("Go-GARCH: JALSHTR_Index")


print(gg_go_equity)

# prop

gg_go_prop <- ggplot(gog.time.var.cor %>%

                         dplyr::filter(grepl("JSAPYTR_Index_", Pairs),

                        !grepl("_JSAPYTR_Index", Pairs))) +

    geom_line(aes(x = date, y = Rho,
         colour = Pairs)) + theme_hc() + ggtitle("Go-GARCH: JSAPYTR_Index")

print(gg_go_prop)

# gold

gg_go_gold <- ggplot(gog.time.var.cor %>%

                         dplyr::filter(grepl("Gold_", Pairs),

                                !grepl("_Gold", Pairs))) +

    geom_line(aes(x = date, y = Rho,
                  colour = Pairs)) + theme_hc() + ggtitle("Go-GARCH: Gold")

print(gg_go_gold)

# bitcoin

gg_go_bitcoin <- ggplot(gog.time.var.cor %>%

                         dplyr::filter(grepl("Bitcoin_", Pairs),

                                !grepl("_Bitcoin", Pairs))) +

    geom_line(aes(x = date, y = Rho,
                  colour = Pairs)) + theme_hc() + ggtitle("Go-GARCH: Bitcoin")
```


```{r}
print(gg_go_equity)
```


```{r}
print(gg_go_prop)
```


```{r}
print(gg_go_gold)

```


```{r}
print(gg_go_bitcoin)
```


```{r}
#plot_grid(finplot(gg_go_equity), finplot(gg_go_prop),

#          finplot(gg_go_gold), finplot(gg_go_bitcoin),

#          labels = list(title = ""),
#          label_size = ggpts(30), align = "h")
################################################
```


The most noticeable difference between the GO-GARCH correlations and the DCC correlations is the range in which they vary. Similar to @boswijk2006wake I find that the GO-GARCH and DCC correlation patterns are similar, however, from my analyse I do not find that the GO-GARCH model behaves like a smoothed version of the DCC model. Furthermore, the difference between these two models should be interpreted with caution since this property may be favourable to some and not others.


# Portfolio optimization

In the final section of this paper, I use the data on equities, property, gold and Bitcoin to optimize three portfolios with a linear constraint of long only. In particular, I construct an equal weight portfolio, a global minimum variance portfolio, and a tangency portfolio. The equal weight portfolio gives equal weights of 25 percent to each of the assets in the portfolio. The global minimum portfolio refers to a portfolio that has the minimum possible risk or variance among all possible portfolios constructed from the set of assets. In other words, it is the portfolio with the lowest possible risk among all portfolios with a given expected return. Finally, the tangency portfolio is a portfolio that lies on the efficient frontier and is the portfolio with the highest Sharpe ratio. The Sharpe ratio is a measure of the risk-adjusted return of an investment, defined as the excess return over the risk-free rate divided by the standard deviation of the investment's returns [@sharpe1966mutual].


The pie charts below illustrate the optimal weighting as defined by the equally weighted, global minimum, and tangency portfolios', respectively. As expected, we see that Bitcoin receives a very small weighting (1.3%) in the global minimum portfolio since it is deemed high risk. 

```{r, include=FALSE}
# efficiency portfolio
library(timeSeries)
library(fPortfolio)
all.data <- as.timeSeries(100*asset_xts_ret)

# equal weight

ewSpec <- portfolioSpec(portfolio = list(weights=rep(1, NCOL(asset_xts_ret))/NCOL(asset_xts_ret) ))

ewportfolio <- feasiblePortfolio(data = all.data,spec = ewSpec, constraints = "LongOnly")

#print(ewportfolio)

minriskSpec <- portfolioSpec()

targetReturn <- getTargetReturn(ewportfolio@portfolio)["mean"]

`setTargetReturn<-`(minriskSpec,targetReturn)

#now we optimise

minRiskPortfolio <- efficientPortfolio(data = all.data, spec = minriskSpec,
                                       constraints = "LlongOnly")

#print(minRiskPortfolio)
# tangency portfolio

Tangecy_Portfolio <- tangencyPortfolio(data = all.data, spec = minriskSpec,
                                       constraints = "LongOnly")

#print(Tangecy_Portfolio)

#######################################
```

```{r}

weightsPie(ewportfolio, box = FALSE)

```

```{r}
weightsPie(minRiskPortfolio, box = FALSE)

```

```{r}
weightsPie(Tangecy_Portfolio, box = FALSE)


```

```{r}

portFrontier <- portfolioFrontier(all.data)

fPortfolio::weightsPlot(portFrontier)

```

The figure above is another interesting chart that displays the weights on the different assets, the risk, and the return along the frontier. The black line through the chart indicates the minimum variance portfolio. 

Next, I present the performance summary charts which sums up the information we need in analysing all the portfolios’ performance over time. The charts depict each portfolio’s cumulative return, daily return, and drawdown. Each portfolio is rebalanced every quarter.

```{r, include=FALSE}
#Portfolio Daily Return Rebalance every Quarters
ew <- rep(1, NCOL(asset_xts_ret))/NCOL(asset_xts_ret)

Portfolio_Return <- Return.portfolio(asset_xts_ret, weights = ew,
                                     rebalance_on = 'quarters')

#Portfolio Returns Distribution on Period

chart.Histogram(Portfolio_Return,
                main = "Portfolio Daily Returns Distributions (2013-2020)",
                cex.axis = 1.2, cex.lab = 1.5, cex.main = 2,
                colorset = "#F77171",
                note.line = mean(Return.portfolio(asset_xts_ret)),
                note.label = 'Average', note.color = 'black', note.cex = 1.2)
```

```{r}
charts.PerformanceSummary(Portfolio_Return,
                          main = 'Equally Weighted Portfolio Performance')

```

```{r, include=FALSE}
#min risk weights

minriskweight <- as.numeric(c(0.2557, 0.2060, 0.5257, 0.0126))

#Portfolio Daily Return Rebalance every Quarters

Portfolio_Return_minrisk <- Return.portfolio(asset_xts_ret, weights = minriskweight,
                                     rebalance_on = 'quarters')

#Portfolio Returns Distribution on Period

chart.Histogram(Portfolio_Return_minrisk,
                main = "Portfolio Daily Returns Distributions (2013-2020)",
                cex.axis = 1.2, cex.lab = 1.5, cex.main = 2,
                colorset = "#F77171",
                note.line = mean(Return.portfolio(asset_xts_ret)),
                note.label = 'Average', note.color = 'black', note.cex = 1.2)
```

```{r}
charts.PerformanceSummary(Portfolio_Return_minrisk,
                          main = 'Global Min Variance Portfolio Performance')

```

```{r, include=FALSE}
#Tangency weights

tangent_weight <- as.numeric(c(0.4906, 0.0000, 0.3534, 0.1560))
#Portfolio Daily Return Rebalance every Quarters

Portfolio_Return_tangent <- Return.portfolio(asset_xts_ret, weights = tangent_weight,
                                             rebalance_on = 'quarters')

#Portfolio Returns Distribution on Period

chart.Histogram(Portfolio_Return_tangent,
                main = "Portfolio Daily Returns Distributions (2013-2020)",
                cex.axis = 1.2, cex.lab = 1.5, cex.main = 2,
                colorset = "#F77171",
                note.line = mean(Return.portfolio(asset_xts_ret)),
                note.label = 'Average', note.color = 'black', note.cex = 1.2)
```

```{r}
charts.PerformanceSummary(Portfolio_Return_tangent,
                          main = 'Tangency Portfolio Performance')



```


Finally, the table displays the target returns and risks associated with each portfolio.

$$
\begin{array}{|c|c|c|c|c|}
\hline \text { Portfolio } & \text { Mean Return } & \text { Cov } & \text { CVaR } & \text { VaR }  \\
\hline \text { Equally Weighted } & { 0.0464 } & {1.1288 } & {2.7860 } & {1.8735 }\\
\text { Global Minimum Variance } & {0.0149 } & {0.5473 } & {1.2432} & {0.9095 } \\
\text { Tangency } & {0.0383 } & {0.8425 } & {1.9634 } & {1.3444 } \\
\hline
\end{array}
$$

It is surprising that the expected returns of the equally weighted portfolio are higher than the tangency portfolio. However, from the figure displaying the weights along the frontier we see that as the amount of risk increases the weights assigned to the property index decreases. Thus, it could be that the tangency portfolio deems property stocks to risky relative to its return series, hence assigning it a weight if zero. 

Conditional Value at Risk (CVaR) is a risk measure that quantifies the expected loss for a portfolio or investment for a given confidence level. It provides a more complete picture of the risk associated with an investment by focusing on the tail risk and providing information about the potential losses in the worst-case scenarios. It is evident that the equally weighted portfolio has the highest expected loss followed by the tangency portfolio and the global minimum portfolio. By considering both the mean return and the CVaR, it seems that the risk and return trade-off for an equally weighted portfolio is quite high. As such, the tangency portfolio appears to perform the best, even though its mean return is slightly lower. 

# Conclusion

In conclusion, this study on asset class correlations and portfolio optimization has shown the importance of considering the relationships between assets when constructing a portfolio. By analysing the covariance between assets, investors can better understand the risk associated with the interactions between the assets in their portfolio and make informed decisions about the risk and return trade-off.

The study also highlighted the potential benefits of portfolio optimization in terms of improving risk-adjusted returns and reducing portfolio risk. By using optimization techniques, investors can identify portfolios that lie on the efficient frontier and achieve the highest possible return for a given level of risk, or the lowest possible risk for a given level of return.

Furthermore, the study demonstrated the significance of regularly monitoring and adjusting portfolios in response to changes in the market and in the correlations between assets. By keeping up-to-date with market developments and making necessary changes, investors can maintain a well-diversified portfolio that is better suited to their investment goals.






\newpage

# References {-}

<div id="refs"></div>



